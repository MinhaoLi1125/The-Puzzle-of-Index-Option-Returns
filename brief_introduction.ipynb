{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3410580"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('./data/pulled/OptionMetrics.parquet')\n",
    "\n",
    "df.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>secid</th>\n",
       "      <th>exdate</th>\n",
       "      <th>cp_flag</th>\n",
       "      <th>strike_price</th>\n",
       "      <th>forward_price</th>\n",
       "      <th>impl_volatility</th>\n",
       "      <th>volume</th>\n",
       "      <th>contract_size</th>\n",
       "      <th>best_bid</th>\n",
       "      <th>best_offer</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>tb_m3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996-01-05</td>\n",
       "      <td>108105.0</td>\n",
       "      <td>1996-03-16</td>\n",
       "      <td>C</td>\n",
       "      <td>525000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.8750</td>\n",
       "      <td>93.875</td>\n",
       "      <td>617.7</td>\n",
       "      <td>616.71</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1996-01-05</td>\n",
       "      <td>108105.0</td>\n",
       "      <td>1996-03-16</td>\n",
       "      <td>C</td>\n",
       "      <td>550000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>68.7500</td>\n",
       "      <td>69.750</td>\n",
       "      <td>617.7</td>\n",
       "      <td>616.71</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1996-01-05</td>\n",
       "      <td>108105.0</td>\n",
       "      <td>1996-02-17</td>\n",
       "      <td>C</td>\n",
       "      <td>570000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.116110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>48.2500</td>\n",
       "      <td>49.250</td>\n",
       "      <td>617.7</td>\n",
       "      <td>616.71</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1996-01-05</td>\n",
       "      <td>108105.0</td>\n",
       "      <td>1996-03-16</td>\n",
       "      <td>P</td>\n",
       "      <td>550000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.179154</td>\n",
       "      <td>623.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.375</td>\n",
       "      <td>617.7</td>\n",
       "      <td>616.71</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1996-01-05</td>\n",
       "      <td>108105.0</td>\n",
       "      <td>1996-01-20</td>\n",
       "      <td>P</td>\n",
       "      <td>525000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.353404</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.125</td>\n",
       "      <td>617.7</td>\n",
       "      <td>616.71</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date     secid      exdate cp_flag  strike_price forward_price  \\\n",
       "0 1996-01-05  108105.0  1996-03-16       C      525000.0          None   \n",
       "1 1996-01-05  108105.0  1996-03-16       C      550000.0          None   \n",
       "2 1996-01-05  108105.0  1996-02-17       C      570000.0          None   \n",
       "3 1996-01-05  108105.0  1996-03-16       P      550000.0          None   \n",
       "4 1996-01-05  108105.0  1996-01-20       P      525000.0          None   \n",
       "\n",
       "   impl_volatility  volume  contract_size  best_bid  best_offer   open  \\\n",
       "0              NaN     0.0          100.0   92.8750      93.875  617.7   \n",
       "1              NaN     0.0          100.0   68.7500      69.750  617.7   \n",
       "2         0.116110     0.0          100.0   48.2500      49.250  617.7   \n",
       "3         0.179154   623.0          100.0    1.0000       1.375  617.7   \n",
       "4         0.353404   100.0          100.0    0.0625       0.125  617.7   \n",
       "\n",
       "    close  tb_m3  \n",
       "0  616.71   5.03  \n",
       "1  616.71   5.03  \n",
       "2  616.71   5.03  \n",
       "3  616.71   5.03  \n",
       "4  616.71   5.03  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## level 1 filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**“Identical” Filter:** The OptionMetrics data set contain duplicate observations, defined as two or more quotes with identical option type, strike, expiration date, and price. In each such case, we eliminate all but one of the quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_quotes(df):\n",
    "    \"\"\"\n",
    "    Removes duplicate observations from the OptionMetrics dataset.\n",
    "    Duplicates are defined as quotes with the same option type, strike price,\n",
    "    expiration date, and price.\n",
    "    \n",
    "    Parameters:\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing the OptionMetrics dataset.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame\n",
    "        DataFrame with duplicate observations removed.\n",
    "    \"\"\"\n",
    "    # Criteria for defining duplicates: option type, strike price, expiration date, and price\n",
    "    cols_to_check = ['secid', 'cp_flag', 'strike_price','date','exdate', 'best_offer']\n",
    "    \n",
    "    # Remove duplicates, keeping the first occurrence\n",
    "    df_unique = df.drop_duplicates(subset=cols_to_check, keep='first')\n",
    "    \n",
    "    return df_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df_1 = remove_duplicate_quotes(df)\n",
    "print(df.shape[0]-df_1.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**“Identical Except Price” Filter:** There are a few sets of quotes with identical\n",
    " terms (type, strike, and maturity) but different prices. When this occurs, we\n",
    " keep the quote whose T-bill-based implied volatility is closest to that of its\n",
    " moneyness neighbors, and delete the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_options_data(df):\n",
    "    \"\"\"\n",
    "    Cleans a DataFrame of options data by removing duplicates based on certain\n",
    "    criteria (type, strike, maturity, date), while keeping the entry whose\n",
    "    implied volatility is closest to the TBill based implied volatility of its\n",
    "    moneyness neighbors.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing options data with columns for 'secid', 'date',\n",
    "          'cp_flag', 'strike_price', 'exdate', 'close', and 'impl_volatility'.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with duplicates removed based on the specified logic.\n",
    "    \"\"\"\n",
    "    # Calculate moneyness for each option\n",
    "    df['moneyness'] = (df['strike_price'] / 1000) / df['close']\n",
    "\n",
    "    # Identify all duplicates based on the given subset of columns\n",
    "    duplicates_mask = df.duplicated(subset=['secid', 'date', 'cp_flag', 'strike_price', 'exdate'], keep=False)\n",
    "\n",
    "    # Separate duplicates for further analysis\n",
    "    df_duplicates = df[duplicates_mask]\n",
    "    df_unique = df[~duplicates_mask]\n",
    "\n",
    "    # Find moneyness neighbors and the implied volatility closest to TBill for each duplicate\n",
    "    df_duplicates = df_duplicates.sort_values(by=['secid', 'cp_flag', 'date', 'exdate'])\n",
    "    grouped = df_duplicates.groupby(['secid', 'cp_flag', 'date', 'exdate'])\n",
    "\n",
    "    closest_to_tbill = grouped.apply(lambda x: x.loc[(x['moneyness'] - 1).abs().idxmin()])\n",
    "\n",
    "\n",
    "    # Drop duplicates in the original duplicates DataFrame and keep only the closest entries\n",
    "    df_cleaned_duplicates = closest_to_tbill.drop_duplicates(subset=['secid', 'date', 'cp_flag', 'strike_price', 'exdate'])\n",
    "\n",
    "    # Combine the non-duplicate entries with the cleaned duplicates and sort\n",
    "    df_final = pd.concat([df_unique, df_cleaned_duplicates]).sort_values(by=['secid', 'cp_flag', 'date', 'exdate']).reset_index(drop=True)\n",
    "\n",
    "    # Cleanup: remove temporary columns if needed\n",
    "    df_final.drop(['moneyness'], axis=1, inplace=True)\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HuYun\\AppData\\Local\\Temp\\ipykernel_22220\\2478406180.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  closest_to_tbill = grouped.apply(lambda x: x.loc[(x['moneyness'] - 1).abs().idxmin()])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "df_2 = clean_options_data(df_1)\n",
    "print(df_1.shape[0]-df_2.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**“Bid = 0” Filter:** We remove quotes of zero for bids, thereby avoiding low\n",
    "valued options. Also, a zero bid may indicate censoring as negative bids\n",
    " cannot be recorded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_zero_bid_filter(df):\n",
    "    \"\"\"\n",
    "    Filters out rows from the DataFrame where the 'best_bid' value is zero.\n",
    "    Rows with a 'best_bid' of zero might be considered as having no active bids,\n",
    "    which could be irrelevant for certain analyses focusing on active market participation.\n",
    "\n",
    "    Parameters:\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing options data with a 'best_bid' column.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame\n",
    "        A filtered DataFrame with rows having non-zero 'best_bid' values.\n",
    "    \"\"\"\n",
    "    filtered_df = df.query(\"best_bid != 0.0\")\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272078\n"
     ]
    }
   ],
   "source": [
    "df_3 = delete_zero_bid_filter(df_2)\n",
    "print(df_2.shape[0]-df_3.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## level 2 filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**“Days to Maturity <7 or >180 ” Filter:** We remove all options with fewer than seven or more than 180 calendar days to expiration. The short maturity op- tions tend to move erratically close to expiration and the long maturity op- tions lack volume and open interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DaystoMaturity_filter(df):\n",
    "    df['exdate'] = pd.to_datetime(df['exdate'])\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['T-t'] = (df['exdate'] - df['date']).dt.days\n",
    "    df = df[df['T-t'] > 7]\n",
    "    df = df[df['T-t'] < 180]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**“IV<5% or >100%” Filter:**  We remove all option quotes with implied vola- tilities lower than 5% or higher than 100%, computed using T-bill interest rates. Such extreme values likely indicate quotation problems or simply low value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtremeIV_filter(df):\n",
    "    df = df[df['impl_volatility'] > 0.05]\n",
    "    df = df[df['impl_volatility'] < 1.0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**“Moneyness <0.8 or >1.2” Filter:** We remove all option quotes with money- ness, the ratio of strike price to index price, below 0.8 or above 1.2. These options have little value beyond their intrinsic value and are also very thinly traded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moneyness_filter(df):\n",
    "    df['strike_price']=df['strike_price']/1000\n",
    "    df['ratio'] = df['close'] / df['strike_price']\n",
    "\n",
    "    df_filtered = df[(df['ratio'] >= 0.8) & (df['ratio'] <= 1.2)]\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**“Implied Interest Rate <0” Filter**: We need to check whether the implied interest rate in the pairs of options is abnormal. Abnormal implied interest rate shows an error in data or mispricing. To construct this rate, we take all put-call pairs of a given maturity and impose put-call parity using the bid-ask midpoint as the price, and allowing the interest rate to adjust. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def implied_interest_rate_filter(df):\n",
    "    #df['avg_price']=df(['best_bid']+df['best_offer'])/2\n",
    "    # Step 1: find pairs of options with same exdate & trike_price\n",
    "    \n",
    "    call_options = df[df['cp_flag'] == 'C']\n",
    "    put_options = df[df['cp_flag'] == 'P']\n",
    "    \n",
    "    \n",
    "    df['date']=pd.to_datetime(df['date'])\n",
    "    \n",
    "    df['exdate']=pd.to_datetime(df['exdate'])\n",
    "    \n",
    "  \n",
    "\n",
    "   #print(merged_options)\n",
    "    call_options['date']=pd.to_datetime(call_options['date'])\n",
    "    \n",
    "    call_options['exdate']=pd.to_datetime(call_options['exdate'])\n",
    "    \n",
    "    put_options['date']=pd.to_datetime(put_options['date'])\n",
    "    \n",
    "    put_options['exdate']=pd.to_datetime(put_options['exdate'])\n",
    "    \n",
    "    # Step 2: calculate average price of each pair of options\n",
    "    call_options['option_price'] = (call_options['best_bid'] + call_options['best_offer']) / 2\n",
    "    put_options['option_price'] = (put_options['best_bid'] + put_options['best_offer']) / 2\n",
    "\n",
    "    # Step 3: calculate implied interest rate\n",
    "    \n",
    "    call_options['time_to_maturity'] = (call_options['exdate'] - call_options['date']).dt.days / 365.25\n",
    "    \n",
    "    put_options['time_to_maturity'] = (put_options['exdate'] - put_options['date']).dt.days / 365.25\n",
    "    \n",
    "    call_options['implied_rate'] = -np.log((call_options['option_price'] - \n",
    "                                            put_options['option_price'] + \n",
    "                                            call_options['close']) / \n",
    "                                            call_options['strike_price']) /call_options['time_to_maturity']\n",
    "    \n",
    "    put_options['implied_rate'] = -np.log((call_options['option_price'] - \n",
    "                                            put_options['option_price'] + \n",
    "                                            put_options['close']) / \n",
    "                                            put_options['strike_price']) /put_options['time_to_maturity']\n",
    "    result_df = pd.concat([call_options,put_options],axis=0)\n",
    "    result_df.sort_values('date')\n",
    "    result_df.drop(result_df[result_df['implied_rate']<=0], axis=1, inplace=True)\n",
    "\n",
    "    return(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**“IV” Filter**:We remove implied volatility outliers and those pairs who are not able to calcultate IV to reduce the prevalence of apparent butterfly arbitrage.\n",
    "\n",
    "For each date and maturity, we fit a quadratic curve (separately to puts and calls) through the observed log implied volatilities. \n",
    "\n",
    "Then we compute a typical (one standard deviation) relative distance in percent from the level of the fitted curve.\n",
    "\n",
    "Finally we check for each option’s IV, how many standard deviations it is apart from the fitted IV curve. These distances are tight in and around the money (about 2%) and wide in the out of the money range (around 3.5%). So we remove the samples whose IV is out of the 2 sigma range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IV_filter(df):\n",
    "    \n",
    "    from scipy.optimize import curve_fit\n",
    "    from scipy.stats import norm\n",
    "\n",
    "    def quadratic(x, a, b, c):\n",
    "        return a * x**2 + b * x + c\n",
    "\n",
    "    \n",
    "    grouped = df.groupby(['date', 'exdate', 'cp_flag'])\n",
    "\n",
    "    # save parameter and stdevs\n",
    "    \n",
    "    fit_params = {}\n",
    "    std_devs = {}\n",
    "   \n",
    "    for name, group in grouped:\n",
    "        params=[1,2,3]\n",
    "        valid_data = group.dropna(subset=['impl_volatility'])\n",
    "        if valid_data.empty:\n",
    "            continue\n",
    "\n",
    "        #generate IV\n",
    "        \n",
    "        log_iv = np.log(valid_data['impl_volatility'].dropna())\n",
    "        #params,_ = curve_fit(quadratic, valid_data['strike_price'], log_iv)\n",
    "        fit_params[name] = params\n",
    "\n",
    "        #calculate IV and calculate residuals\n",
    "        fitted_ivs = quadratic(valid_data['strike_price'], *params)\n",
    "        residuals = log_iv - fitted_ivs\n",
    "\n",
    "        # calculate stdevs of the residual\n",
    "        std_dev = np.std(residuals)\n",
    "        std_devs[name] = std_dev\n",
    "\n",
    "    # filter the outliers that are above or below +-2 stdev\n",
    "    filtered_df = pd.DataFrame()\n",
    "    \n",
    "    for name, group in grouped:\n",
    "        if name not in fit_params or name not in std_devs:\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        \n",
    "        log_iv = np.log(group['impl_volatility'].dropna())\n",
    "        fitted_ivs = quadratic(group['strike_price'], *fit_params[name])\n",
    "        residuals = log_iv - fitted_ivs\n",
    "        \n",
    "    # find the samples within 95% interval\n",
    "        within_confidence_interval = (residuals > -2 * std_devs[name]) & (residuals < 2 * std_devs[name])\n",
    "        \n",
    "        z_score = norm.ppf(0.975)  \n",
    "\n",
    "        filtered_group = group.loc[within_confidence_interval]\n",
    "        filtered_df = pd.concat([filtered_df, filtered_group])\n",
    "    \n",
    "    \n",
    "    return filtered_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**“Put-call Parity” Filter**: For every put-call pair with the same date, maturity, and moneyness, we insure that put-call parity holds and that violations are eliminated. Thus, for each put-call pair, we find the bid-ask midpoint put-call parity-implied interest rate. Next, we trim outliers in a similar way as with the IV filter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parity_filter(df):\n",
    "    \n",
    "    df['parity']=np.zeros(len(df))\n",
    "    \n",
    "    call_options = df[df['cp_flag'] == 'C']\n",
    "    put_options = df[df['cp_flag'] == 'P']\n",
    "    \n",
    "    \n",
    "    df['date']=pd.to_datetime(df['date'])\n",
    "    \n",
    "    df['exdate']=pd.to_datetime(df['exdate'])\n",
    "    \n",
    "  \n",
    "\n",
    "   #print(merged_options)\n",
    "    call_options['date']=pd.to_datetime(call_options['date'])\n",
    "    \n",
    "    call_options['exdate']=pd.to_datetime(call_options['exdate'])\n",
    "    \n",
    "    put_options['date']=pd.to_datetime(put_options['date'])\n",
    "    \n",
    "    put_options['exdate']=pd.to_datetime(put_options['exdate'])\n",
    "    \n",
    "    # Step 2: calculate average price of each pair of options\n",
    "    call_options['option_price'] = (call_options['best_bid'] + call_options['best_offer']) / 2\n",
    "    put_options['option_price'] = (put_options['best_bid'] + put_options['best_offer']) / 2\n",
    "\n",
    "    # Step 3: calculate implied interest rate\n",
    "   \n",
    "    call_options['time_to_maturity'] = (call_options['exdate'] - call_options['date']).dt.days / 365.25\n",
    "    \n",
    "    put_options['time_to_maturity'] = (put_options['exdate'] - put_options['date']).dt.days / 365.25\n",
    "    \n",
    "    call_options['implied_rate'] = -np.log((call_options['option_price'] - \n",
    "                                            put_options['option_price'] + \n",
    "                                            call_options['close']) / \n",
    "                                            call_options['strike_price']) /call_options['time_to_maturity']\n",
    "    \n",
    "    put_options['implied_rate'] = -np.log((call_options['option_price'] - \n",
    "                                            put_options['option_price'] + \n",
    "                                            put_options['close']) / \n",
    "                                            put_options['strike_price']) /put_options['time_to_maturity']\n",
    "    \n",
    "    # Step 4: calculate put call parity difference\n",
    "    \n",
    "    for idx, row in call_options.iterrows():\n",
    "        \n",
    "        put_option_row = put_options.loc[1]\n",
    "        \n",
    "        \n",
    "        parity = (row['option_price'] - put_option_row['option_price'] -\n",
    "                row['close'] + row['strike'] / (1 + row['implied_rate']))\n",
    "        \n",
    "        \n",
    "        call_options.loc[idx, 'parity'] = parity\n",
    "\n",
    "    # for those does not satisfy put-call parity the result will not be zero\n",
    "    result_df=df.drop(result_df[(result_df['parity']<=-0.1)and(result_df['parity']>=0.1)], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    return result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
